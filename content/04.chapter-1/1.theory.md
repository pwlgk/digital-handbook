---
title: '1. Теоретические сведения'
---

# Теория: Энтропия

**Энтропия (H)** в теории информации – это мера неопределенности источника сообщений. Она показывает, какое количество информации в среднем приходится на один символ алфавита.

Формула Шеннона для энтропии:

`H = - Σ pᵢ * log₂(pᵢ)`

где `pᵢ` — вероятность появления i-го символа в сообщении.