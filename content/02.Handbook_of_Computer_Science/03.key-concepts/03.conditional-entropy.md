---
title: 'Условная энтропия и цепи Маркова'
description: 'Свойства условной вероятности, дискретные источники с памятью и основы теории цепей Маркова.'
---

# Условная энтропия и цепи Маркова

## I. Свойства условной вероятности

Обозначим $P(B|A)$ – вероятность наступления события B при условии, что A уже произошло.
Для одновременного наступления двух событий A и B верно $P(AB) = P(A) \cdot P(B|A)$.
Если A и B независимы, то $P(B|A) = P(B)$ и $P(AB) = P(A) \cdot P(B)$.
Симметрично $P(BA) = P(B) \cdot P(A|B)$, значит, $P(B) \cdot P(A|B) = P(A) \cdot P(B|A)$.

Формула условной вероятности:

$$
P(A|B) = \frac{P(AB)}{P(B)} = \frac{P(A|B) \cdot P(B)}{P(B)}.
$$

Формула Байеса:

$$
P(B|A) = \frac{P(A|B) \cdot P(B)}{P(A)}.
$$

События $B_1, B_2, \dots, B_n$ образуют полную группу, если они попарно несовместны и $\sum_{i=1}^n P(B_i) = 1$. В этом случае верна формула полной вероятности $P(A) = \sum_{i=1}^n P(AB_i) = \sum_{i=1}^n P(A|B_i) \cdot P(B_i)$.

Методы расчета условной энтропии приведены в [главе 2](/path/to/chapter-2). <!-- Замените /path/to/chapter-2 на реальный путь -->

---

## II. Дискретные источники с памятью

Дискретный источник с памятью (ДИСП) размера $r$ и алфавитом $x_1, x_2, \dots, x_N$ задается множеством состояний $\{S_1, S_2, \dots, S_M\}$, $M=N^r$; вероятностями $p_{ij}^{(l)}$ появления символа $x_l$ в состоянии $S_i$; графом переходов из состояния $S[n] = (x[n-r], x[n-r+1], \dots, x[n-1])$ в $S[n+1] = (x[n-r+1], x[n-r+2], \dots, x[n])$ после появления очередного символа $x[n]$; начальным распределением состояний $\mathbf{p}_0 = (p_0(1), p_0(2), \dots, p_0(M))$.
Совместные энтропии возрастающих последовательностей символов: $H(X_1X_2)$, $H(X_1X_2X_3)$, дают в среднем на один символ энтропию

$$
H_L(X) = \frac{1}{L} H(X_1X_2\dots X_L).
$$

Условная энтропия L-го символа: $H(X_L | X_1X_2\dots X_{L-1})$.

Теорема. $\lim_{L \to \infty} H(X_L | X_1X_2\dots X_{L-1}) = \lim_{L \to \infty} H_L(X) = H_{\infty}(X)$.

---

## III. Цепи Маркова

Математической моделью ДИСП является цепь Маркова. Это последовательность состояний $S[1], S[2], \dots, S[n], \dots$, каждое из которых принадлежит множеству $\{S_1, S_2, \dots, S_M\}$, и заданные вероятности перехода $\pi_{n_2n_1}(j_2|j_1) = P(S[n_2]=S_{j_2} | S[n_1]=S_{j_1})$.
Они должны удовлетворять следующим свойствам:

1.  $\sum_{j_2=1}^M \pi_{n_2n_1}(j_2|j_1) = 1$ (полная группа);
2.  $\pi_{n_3n_1}(j_3|j_1) = \sum_{j_2=1}^M \pi_{n_3n_2}(j_3|j_2) \cdot \pi_{n_2n_1}(j_2|j_1)$ (равенство Колмогорова – Чепмена).

Для стационарного ДИСП (независимого от начала отсчета времени) достаточно задать $\pi_{n_1+1, n_1}(j_2|j_1) = P(S[n+1]=S_{j_2} | S[n]=S_{j_1})$, т.е. матрицу

$$
\Pi = \begin{pmatrix}
\pi_{n+1,n}(1|1) & \pi_{n+1,n}(1|2) & \dots & \pi_{n+1,n}(1|M) \\
\pi_{n+1,n}(2|1) & \pi_{n+1,n}(2|2) & \dots & \pi_{n+1,n}(2|M) \\
\dots & \dots & \dots & \dots \\
\pi_{n+1,n}(M|1) & \pi_{n+1,n}(M|2) & \dots & \pi_{n+1,n}(M|M)
\end{pmatrix}.
$$

Тогда по равенству Колмогорова – Чепмена находим $\mathbf{p}_n = (p_n(1), p_n(2), \dots, p_n(M)) = \mathbf{p}_0 \cdot \Pi^n$, где $\mathbf{p}_0 = (p_0(1), p_0(2), \dots, p_0(M))$.
Из эргодичности ДИСП следует регулярность цепи Маркова, т.е. существование предела $\Pi_{\infty} = \lim_{n \to \infty} \Pi^n$. Все строки матрицы $\Pi_{\infty}$ равны предельному распределению $\mathbf{p}_{\infty} = (p_{\infty}(1), p_{\infty}(2), \dots, p_{\infty}(M))$, являющемуся собственным вектором: $\mathbf{p}_{\infty} = \mathbf{p}_{\infty} \Pi$.
Энтропия в этом случае равна $H_{\infty}(X) = \sum_{j=1}^M p_{\infty}(j) H(X|S_j)$, где

$$
H(X|S_j) = -\sum_{i=1}^N p_{ji}^{(l)} \log p_{ji}^{(l)}.
$$