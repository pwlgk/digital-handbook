---
title: '2. Примеры'
description: 'Пример кодирования по методу Хаффмана для русского алфавита.'
---

## 3.2. Примеры

### Пример 1.

Заданы вероятности появления букв русского языка в тексте. Вычислить энтропию и избыточность. Провести кодирование по методу Хаффмана, вычислить среднюю длину кодового слова и эффективность кода.

<div class="full-width">

| Буква | Вероятность | Буква | Вероятность | Буква | Вероятность | Буква | Вероятность |
| :---: | :---------: | :---: | :---------: | :---: | :---------: | :---: | :---------: |
|   о   |    0,096    |   к   |    0,029    |   ф   |    0,002    |   щ   |    0,003    |
|   а   |    0,065    |   м   |    0,026    |   х   |    0,009    |   ъ   |    0,014    |
|   н   |    0,059    |   д   |    0,026    |   ц   |    0,004    |   ы   |    0,016    |
|   т   |    0,056    |   п   |    0,024    |   ч   |    0,013    |   ь   |    0,015    |
|   е   |    0,074    |   у   |    0,021    |   ш   |    0,006    |   э   |    0,003    |
|   ж   |    0,008    |   я   |    0,019    | пробел|    0,143    |   ю   |    0,007    |
|   и   |    0,064    |   б   |    0,016    |       |             |   я   |    0,019    |

</div>

В программе OpenOffice Calc вводим заданные вероятности букв в один столбец. Расчет энтропии проводится так же, как в [примере 2 главы 1](/path/to/chapter1-example2).

|    | A      | B      |
|:---|:-------|:-------|
| **15** | о      | 0,096  |
| **16** | п      | 0,024  |
| **17** | р      | 0,041  |
| **18** | с      | 0,047  |
| **19** | т      | 0,056  |
| **20** | у      | 0,021  |
| **21** | ф      | 0,002  |
| **22** | х      | 0,009  |
| **23** | ц      | 0,004  |
| **24** | ч      | 0,013  |
| **25** | ш      | 0,006  |
| **26** | щ      | 0,003  |
| **27** | ъ      | 0,014  |
| **28** | ы      | 0,016  |
| **29** | ь      | 0,015  |
| **30** | э      | 0,003  |
| **31** | ю      | 0,007  |
| **32** | я      | 0,019  |
| **33** | пробел | 0,143  |
| **34** | ИТОГО  | 1,000  |

Энтропия H(X)=4,414 бит. Если бы все буквы имели одинаковые вероятности, то энтропия должна была бы равняться максимальной: $H_{max} = \log_2 N = \log_2 32 = 5$ бит. Избыточность равна $D = H_{max} - H(X) = 5 - 4,414 = 0,586$ бит.

Копируем первые два столбца на другой лист (без итоговой строки) и проводим сортировку. Для этого выделяем нужный диапазон и вызываем команду меню «Данные-Сортировка». Затем рядом и проводим объединение последних двух знаков в один.

|    | A   | B      |   | C   | D      |
|:---|:----|:-------|:--|:----|:-------|
| **12** | к   | 0,029  |   | к   | 0,029  |
| **13** | м   | 0,026  |   | м   | 0,026  |
| **14** | д   | 0,026  |   | д   | 0,026  |
| **15** | п   | 0,024  |   | п   | 0,024  |
| **16** | у   | 0,021  |   | у   | 0,021  |
| **17** | я   | 0,019  |   | я   | 0,019  |
| **18** | ы   | 0,016  |   | ы   | 0,016  |
| **19** | ь   | 0,015  |   | ь   | 0,015  |
| **20** | ъ   | 0,014  |   | ъ   | 0,014  |
| **21** | ч   | 0,013  |   | ч   | 0,013  |
| **22** | ю   | 0,007  |   | ю   | 0,007  |
| **23** | щ   | 0,006  |   | щ   | 0,006  |
| **24** | э   | 0,003  |   | э+ф | 0,005  |
| **25** | ф   | 0,002  |   |     |        |

Складываем вероятности вручную и впечатываем результат. Использование формул здесь бесполезно, так как при дальнейшей сортировке адресация будет непредсказуемой. Начинаем строить декодирующее дерево.

:MermaidDiagram{code="
graph TD
    A(э+ф) -->|0| B(э)
    A -->|1| C(ф)
"}

Повторяем процедуру: сортировка, копирование, объединение последних двух знаков в один.

|    | A   | B      |   | D   | E      |   | G   | H      |
|:---|:----|:-------|:--|:----|:-------|:--|:----|:-------|
| **11** | л   | 0,036  |   | л   | 0,036  |   | л   | 0,036  |
| **12** | к   | 0,029  |   | к   | 0,029  |   | к   | 0,029  |
| **13** | м   | 0,026  |   | м   | 0,026  |   | м   | 0,026  |
| **14** | д   | 0,026  |   | д   | 0,026  |   | д   | 0,026  |
| **15** | п   | 0,024  |   | п   | 0,024  |   | п   | 0,024  |
| **16** | у   | 0,021  |   | у   | 0,021  |   | у   | 0,021  |
| **17** | я   | 0,019  |   | я   | 0,019  |   | я   | 0,019  |
| **18** | ы   | 0,016  |   | ы   | 0,016  |   | ы   | 0,016  |
| **19** | ь   | 0,015  |   | ь   | 0,015  |   | ь   | 0,015  |
| **20** | ъ   | 0,014  |   | ъ   | 0,014  |   | ъ   | 0,014  |
| **21** | ч   | 0,013  |   | ч   | 0,013  |   | ч   | 0,013  |
| **22** | ю   | 0,007  |   | ю   | 0,007  |   | ю   | 0,007  |
| **23** | щ   | 0,006  |   | щ   | 0,006  |   | ц+щ | 0,007  |
| **24** | э+ф | 0,005  |   | э+ф | 0,005  |   |     |        |
| **25** | ц   | 0,004  |   | ц   | 0,004  |   |     |        |

Декодирующее дерево растет с каждым шагом вверх.

<div style="display: flex; justify-content: space-around; align-items: flex-start;">

:MermaidDiagram{code="
graph TD
    A(э+ф) -->|0| B(э)
    A -->|1| C(ф)
"}

:MermaidDiagram{code="
graph TD
    A(ц+щ) -->|0| B(ц)
    A -->|1| C(щ)
"}

:MermaidDiagram{code="
graph TD
    A(ю)
"}

</div>

После тридцати шагов получится примерно следующее:

<div class="full-width">

| CA   | CB    | CC    | CD      | CE    | CF      | CG      | CH      | CI      | CK      | CL      | CM      |
|:-----|:------|:------|:--------|:------|:--------|:--------|:--------|:--------|:--------|:--------|:--------|
| б+э+ф+ъ | 0,226 | ю+ц+щ | 0,226 | пробел+а | 0,308   | о+е     | 0,271   | э+ф+ъ+ч+ю+ц+щ | 0,308   | ...     | ...     |
| мягкого | 0,195 | мягкого | 0,226 | пробел+а | 0,271   | о+е     | 0,195   | ...     | ...     | ...     | ...     |
| мягкого | 0,195 | мягкого | 0,195 | пробел+а | 0,195   | о+е     | 0,195   | ...     | ...     | ...     | ...     |
| пробел | 0,143 | пробел | 0,143 | пробел+а | 0,143   | о+е     |         | ...     | ...     | ...     | ...     |
| пробел | 0,143 |       |       |         |         |         |         | ...     | ...     | ...     | ...     |
| итого | 0,128 |       |       |         |         |         |         | ...     | ...     | ...     | ...     |

</div>

> *Примечание: таблица выше является иллюстрацией промежуточных шагов объединения символов с наименьшими вероятностями. Полная таблица со всеми 30 шагами очень громоздкая и здесь опущена.*

Поскольку объединение очевидно, его можно не фиксировать в отдельной ячейке. Необходимо только на каждом шаге проверять, что суммарная вероятность равна 1. Если где-то произойдет ошибка, то придется переделывать всю работу, начиная с места исправления ошибки.

Декодирующее дерево невозможно сразу нарисовать без «переплетений» и «пересечений». Поэтому рекомендуется перерисовать его «начисто» с соблюдением одинаковой высоты узлов, находящихся на одном уровне.

Проходя по декодирующему дереву от корня к каждой букве, получим ее код. Коды и их длины заносим в первоначальную таблицу (там, где буквы в алфавитном порядке). Средняя длина есть сумма произведений длин на соответствующие вероятности, т.е. используем функцию `SUMPRODUCT()`.

<div class="full-width">

|    | A   | B      | C       | D      | E |
|:---|:----|:-------|:--------|:-------|:--|
| **16** | п   | 0,024  | 011000  | 00001  | 6 |
| **17** | р   | 0,041  | 01101   | 000001 | 5 |
| **18** | с   | 0,047  | 1101    | 1101   | 4 |
| **19** | т   | 0,056  | 1011    | 1011   | 4 |
| **20** | у   | 0,021  | 111100  | 000100 | 6 |
| **21** | ф   | 0,002  | 0010000 | 0010000| 8 |
| **22** | х   | 0,009  | 001001  | 001001 | 6 |
| **23** | ц   | 0,004  | 0010001 | 001011 | 7 |
| **24** | ч   | 0,013  | 0011    | 0011   | 6 |
| **25** | ш   | 0,006  | 001011  | 0000001| 8 |
| **26** | щ   | 0,003  | 001010  | 100001 | 8 |
| **27** | ъ   | 0,014  | 00001   | 100011 | 6 |
| **28** | ы   | 0,016  | 100011  | 00101  | 6 |
| **29** | ь   | 0,015  | 001101  | 001101 | 6 |
| **30** | э   | 0,003  | 100000  | 100000 | 7 |
| **31** | ю   | 0,007  | 000101  | 000101 | 6 |
| **32** | я   | 0,019  | 011001  | 011    | 6 |
| **33** | пробел | 0,143  | 011     | 011    | 3 |
| **34** | ИТОГО | 1,000  | 4,439   |        |   |

</div>

Эффективность полученного кода $R = 4,414 / 4,439 = 0,994$ (99,4%).

   ##### © Бесценный И.П.